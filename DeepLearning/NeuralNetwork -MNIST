import numpy as  np
import random
import loader

def sigmoid(z):
    return 1 / (1 + np.exp(-z))

class Network(object):
    def __init__(self,sizes):
        self.num_layer = len(sizes)
        self.sizes = sizes
        self.weights = [np.random.randn(y,x) for x,y in zip(sizes[:-1],sizes[1:])]
        self.bias = [np.random.randn(y,1) for y in sizes[1:]]

    def sigmoid(self,z):
        return 1/(1+np.exp(-z))

    def sigmoid_prime(self,z):
        return self.sigmoid(z) * (1 - sigmoid(z))

    def feedForward(self,a):
        for w, b in zip(self.weights,self.bias):
            a = self.sigmoid(np.dot(w,a)+b)
        return a

    def  SGD(self,traning_data,epochs,eta,mini_batch_size,test_data = None):
        if test_data:
            n_test = len(test_data)

        n_traning = len(traning_data)
        for i in range(epochs):
            random.shuffle(traning_data)
            mini_batchs = [traning_data[n:n+mini_batch_size] for n in range(0,n_traning,mini_batch_size)]
            for mini_batch in mini_batchs:
                self.update_mini_batch(mini_batch,eta)
                if test_data:
                    print("epoch{0}: {1}/{2}".format(i,self.evaluate(test_data),n_test))
                else:
                    print("epoch{0}".format(i))

    def update_mini_batch(self,mini_batch,eta):
        weights_batch = [np.zeros(w.shape) for w in self.weights]
        bias_batch = [np.zeros(b.shape) for b in self.bias]

        for x,y in mini_batch:
            delta_weight_batch, delta_bias_batch = self.backpropagate(x,y)
            weights_batch  = [wb + dwb for wb, dwb in zip(weights_batch,delta_weight_batch)]
            bias_batch = [bb + dbb for bb, dbb in zip(bias_batch,delta_bias_batch)]
        self.weights = [w - eta/len(mini_batch)* wb for w, wb in zip(self.weights,weights_batch)]
        self.bias = [b - eta/len(mini_batch)* bb for b, bb in zip(self.bias,bias_batch)]

    def backpropagate(self,x,y):
        delta_weights = [np.zeros(w.shape) for w in self.weights]
        delta_bias = [np.zeros(b.shape) for b in self.bias]

        activation = x
        zs = []
        activations = [x]

        #feedforward
        for w, b in zip(self.weights, self.bias):
            z = np.dot(w,activation) + b
            zs.append(z)
            activation = self.sigmoid(z)
            activations.append(activation)

        #propaback
        error = (activations[-1] - y) * self.sigmoid_prime(z)
        delta_bias[-1] = error
        delta_weights[-1] = np.dot(error,activations[-2].transpose())

        for i in range(2,self.num_layer):
            sp = self.sigmoid_prime(zs[-i])
            error = np.dot(self.weights[-i+1].transpose(),error) * sp
            delta_bias[-i] = error
            delta_weights[-i] = np.dot(error,activations[-i-1].transpose())

        return delta_weights, delta_bias

    def evaluate(self, test_data):
        test_results = [(np.argmax(self.feedForward(x)), y) for (x, y) in test_data]
        return sum(int(x == y) for (x, y) in test_results)

training_data, validatioin_data, test_data = loader.load_data_wrapper()
count = 1
print(type(training_data))
for item in training_data:
    count += 1
    print(item)
    if count == 3:
        break

net = Network([784,10])
net.SGD(training_data,5,1.0,50,test_data=test_data)

