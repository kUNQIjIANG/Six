{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(raw_data):\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", raw_data)\n",
    "    words = letters_only.lower().split()\n",
    "    #words = word_tokenize(raw_data)\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    meaningful_words = [w for w in words if not w in stops]\n",
    "    return meaningful_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dirc):\n",
    "    # output a list of string\n",
    "    package = os.listdir(dirc)\n",
    "    string_list = []\n",
    "    for name in package:\n",
    "        file_dir = dirc + name\n",
    "        string_list.append(cleaning(open(file_dir,encoding='latin-1').read()))\n",
    "    return string_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_dire = '/Users/kunqi/Downloads/review-polarity/tokens/pos/'\n",
    "pos_data = load_data(pos_dire)\n",
    "neg_dire = '/Users/kunqi/Downloads/review-polarity/tokens/neg/'\n",
    "neg_data = load_data(neg_dire)\n",
    "all_data = pos_data + neg_data\n",
    "\n",
    "# take all the words appeared into account\n",
    "def word_appeared(word_list):\n",
    "    word_appear = []\n",
    "    for samp in word_list:\n",
    "        for w in samp:\n",
    "            if w not in word_appear:\n",
    "                word_appear.append(w) \n",
    "    return word_appear\n",
    "\n",
    "w_appeared = word_appeared(all_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['undoing', 'wins', 'consequences', 'dire', 'intensely', 'personal', 'filmmaker', 'interiors', 'hearts', 'minds', 'particular', 'trademarks', 'stripped', 'minimalist', 'style', 'flat', 'expressionless', 'dialogue', 'use', 'natural', 'sounds', 'music', 'background', 'twice', 'narration', 'segment', 'credits', 'heavy', 'drumbeat', 'accompanying', 'bagpipes', 'rest', 'scored', 'punctuate', 'thematic', 'elements', 'incessant', 'clanking', 'creaking', 'armor']\n"
     ]
    }
   ],
   "source": [
    "print(w_appeared[200:240])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# order of feature vector will be total number of words appeared\n",
    "def vectorize(to_vec,voc):\n",
    "    vec = [0 for i in range(len(voc))]\n",
    "    for word in to_vec:\n",
    "        vec[voc.index(word)] += 1\n",
    "    return vec\n",
    "\n",
    "def normalize(vec):\n",
    "    return (vec - np.mean(vec))/np.std(vec)\n",
    "\n",
    "def get_set(data,label,voc):\n",
    "    feature_set = []\n",
    "    lable_set = [label for i in range(len(data))]\n",
    "    for sam in data:\n",
    "        vec = np.array(vectorize(sam,voc))\n",
    "        nor = normalize(vec)\n",
    "        feature_set.append(nor)\n",
    "    formed_set = list(zip(feature_set,lable_set))           \n",
    "    return formed_set\n",
    "\n",
    "pos_set = get_set(pos_data,1,w_appeared)\n",
    "neg_set = get_set(neg_data,-1,w_appeared)\n",
    "\n",
    "pos_neg = pos_set + neg_set\n",
    "\n",
    "#split data \n",
    "random.shuffle(pos_neg)\n",
    "training_set = pos_neg[:1000]\n",
    "test_set = pos_neg[1000:]\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1 res -1\n"
     ]
    }
   ],
   "source": [
    "def eu_distance(v1,v2):\n",
    "    return math.sqrt(sum((v1-v2)**2))\n",
    "\n",
    "def KNN_predict(training_set,test_sample,K):\n",
    "    dis_list = []\n",
    "    random.shuffle(training_set)\n",
    "    for point in training_set:\n",
    "        dis_list.append((eu_distance(point[0],test_sample),point[1]))\n",
    "    dis_list.sort(key=operator.itemgetter(0))\n",
    "    top_K = dis_list[:K]\n",
    "    pos = 0\n",
    "    neg = 0\n",
    "    for label in top_K:\n",
    "        if label[1] == 1:\n",
    "            pos += 1\n",
    "        else:\n",
    "            neg += 1\n",
    "    if pos > neg:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "def evaluate(training_set,test_set,K):\n",
    "    test_results = [(KNN_predict(training_set,x,K),y) for (x,y) in test_set]\n",
    "    corr = sum(int(x==y) for (x,y) in test_results)\n",
    "    print(\"accuracy:%f\"%float(corr/len(test_set)))    \n",
    "\n",
    "print(KNN_predict(training_set,test_set[5][0],5),\"res\",test_set[5][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:0.625000\n",
      "elasp time 1336.894073009491\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "evaluate(training_set,test_set,5)\n",
    "end = time.time()\n",
    "print(\"elasp time\",end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
