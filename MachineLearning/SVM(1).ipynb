{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(raw_data):\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", raw_data)\n",
    "    words = letters_only.lower().split()\n",
    "    #words = word_tokenize(raw_data)\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    meaningful_words = [w for w in words if not w in stops]\n",
    "    return meaningful_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dirc):\n",
    "    # output a list of string\n",
    "    package = os.listdir(dirc)\n",
    "    string_list = []\n",
    "    for name in package:\n",
    "        file_dir = dirc + name\n",
    "        string_list.append(cleaning(open(file_dir,encoding='latin-1').read()))\n",
    "    return string_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_dire = '/Users/kunqi/Downloads/review-polarity/tokens/pos/'\n",
    "pos_data = load_data(pos_dire)\n",
    "neg_dire = '/Users/kunqi/Downloads/review-polarity/tokens/neg/'\n",
    "neg_data = load_data(neg_dire)\n",
    "all_data = pos_data + neg_data\n",
    "\n",
    "# take all the words appeared into account\n",
    "def word_appeared(word_list):\n",
    "    word_appear = []\n",
    "    for samp in word_list:\n",
    "        for w in samp:\n",
    "            if w not in word_appear:\n",
    "                word_appear.append(w) \n",
    "    return word_appear\n",
    "\n",
    "w_appeared = word_appeared(all_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['undoing', 'wins', 'consequences', 'dire', 'intensely', 'personal', 'filmmaker', 'interiors', 'hearts', 'minds', 'particular', 'trademarks', 'stripped', 'minimalist', 'style', 'flat', 'expressionless', 'dialogue', 'use', 'natural', 'sounds', 'music', 'background', 'twice', 'narration', 'segment', 'credits', 'heavy', 'drumbeat', 'accompanying', 'bagpipes', 'rest', 'scored', 'punctuate', 'thematic', 'elements', 'incessant', 'clanking', 'creaking', 'armor']\n"
     ]
    }
   ],
   "source": [
    "print(w_appeared[200:240])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# order of feature vector will be total number of words appeared\n",
    "def vectorize(to_vec,voc):\n",
    "    vec = [0 for i in range(len(voc))]\n",
    "    for word in to_vec:\n",
    "        vec[voc.index(word)] += 1\n",
    "    return vec\n",
    "\n",
    "def normalize(vec):\n",
    "    return (vec - np.mean(vec))/np.std(vec)\n",
    "\n",
    "def get_set(data,label,voc):\n",
    "    feature_set = []\n",
    "    lable_set = [label for i in range(len(data))]\n",
    "    for sam in data:\n",
    "        vec = np.array(vectorize(sam,voc))\n",
    "        nor = normalize(vec)\n",
    "        feature_set.append(nor)\n",
    "    formed_set = list(zip(feature_set,lable_set))           \n",
    "    return formed_set\n",
    "\n",
    "pos_set = get_set(pos_data,1,w_appeared)\n",
    "neg_set = get_set(neg_data,-1,w_appeared)\n",
    "\n",
    "pos_neg = pos_set + neg_set\n",
    "\n",
    "#split data \n",
    "random.shuffle(pos_neg)\n",
    "training_set = pos_neg[:1000]\n",
    "test_set = pos_neg[1000:]\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM(object):\n",
    "    def __init__(self,dia):\n",
    "        self.w = np.array([np.random.rand() for i in range(dia)])\n",
    "        self.b = np.random.rand()\n",
    "        \n",
    "    def activation(self,x):\n",
    "        act = 2*self.sigmoid(2*(np.dot(self.w,x) + self.b)) - 1\n",
    "        if act > 0:\n",
    "            return 1\n",
    "        else:\n",
    "            return -1\n",
    "    \n",
    "    def sigmoid(self,t):\n",
    "        return 1/(1+np.exp(-t))\n",
    "    \n",
    "    def train(self,training_data, eta, epoch, test_data):\n",
    "        for i in range(epoch):\n",
    "            sum_se = 0\n",
    "            random.shuffle(training_data)\n",
    "            for point in training_data:\n",
    "                x = point[0]\n",
    "                y = point[1]\n",
    "                error = y - self.activation(x)\n",
    "                sum_se += error ** 2\n",
    "                self.w += eta * error * x\n",
    "                self.b += eta * error\n",
    "            print(\"epoch%d: se:%.3f\" % (i,sum_se))\n",
    "            if test_data:\n",
    "                self.evaluate(test_data)\n",
    "            if sum_se == 0:\n",
    "                break\n",
    "    \n",
    "    def evaluate(self,test_set):\n",
    "        results = [(self.activation(x),y) for (x,y) in test_set]\n",
    "        corr = sum(int(x==y) for (x,y) in results)\n",
    "        print(\"performance: %d/%d\" % (corr,len(test_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1400\n",
      "200\n",
      "0-fold:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel_launcher.py:14: RuntimeWarning: overflow encountered in exp\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0: se:1516.000\n",
      "performance: 138/200\n",
      "epoch1: se:576.000\n",
      "performance: 159/200\n",
      "epoch2: se:208.000\n",
      "performance: 153/200\n",
      "epoch3: se:152.000\n",
      "performance: 164/200\n",
      "epoch4: se:84.000\n",
      "performance: 160/200\n",
      "epoch5: se:8.000\n",
      "performance: 160/200\n",
      "epoch6: se:8.000\n",
      "performance: 162/200\n",
      "epoch7: se:32.000\n",
      "performance: 159/200\n",
      "epoch8: se:16.000\n",
      "performance: 164/200\n",
      "epoch9: se:0.000\n",
      "performance: 164/200\n",
      "Elapsed time for a fold: 2.096766948699951\n",
      "1-fold:\n",
      "epoch0: se:1492.000\n",
      "performance: 138/200\n",
      "epoch1: se:540.000\n",
      "performance: 143/200\n",
      "epoch2: se:196.000\n",
      "performance: 158/200\n",
      "epoch3: se:132.000\n",
      "performance: 163/200\n",
      "epoch4: se:52.000\n",
      "performance: 162/200\n",
      "epoch5: se:16.000\n",
      "performance: 158/200\n",
      "epoch6: se:40.000\n",
      "performance: 157/200\n",
      "epoch7: se:32.000\n",
      "performance: 156/200\n",
      "epoch8: se:16.000\n",
      "performance: 160/200\n",
      "epoch9: se:20.000\n",
      "performance: 160/200\n",
      "epoch10: se:0.000\n",
      "performance: 160/200\n",
      "Elapsed time for a fold: 1.6096088886260986\n",
      "2-fold:\n",
      "epoch0: se:1544.000\n",
      "performance: 153/200\n",
      "epoch1: se:544.000\n",
      "performance: 166/200\n",
      "epoch2: se:164.000\n",
      "performance: 157/200\n",
      "epoch3: se:84.000\n",
      "performance: 156/200\n",
      "epoch4: se:64.000\n",
      "performance: 154/200\n",
      "epoch5: se:56.000\n",
      "performance: 157/200\n",
      "epoch6: se:36.000\n",
      "performance: 160/200\n",
      "epoch7: se:16.000\n",
      "performance: 165/200\n",
      "epoch8: se:12.000\n",
      "performance: 163/200\n",
      "epoch9: se:12.000\n",
      "performance: 163/200\n",
      "epoch10: se:8.000\n",
      "performance: 161/200\n",
      "epoch11: se:28.000\n",
      "performance: 155/200\n",
      "epoch12: se:12.000\n",
      "performance: 165/200\n",
      "epoch13: se:24.000\n",
      "performance: 162/200\n",
      "epoch14: se:12.000\n",
      "performance: 162/200\n",
      "Elapsed time for a fold: 1.957617998123169\n",
      "3-fold:\n",
      "epoch0: se:1560.000\n",
      "performance: 160/200\n",
      "epoch1: se:520.000\n",
      "performance: 142/200\n",
      "epoch2: se:192.000\n",
      "performance: 160/200\n",
      "epoch3: se:172.000\n",
      "performance: 157/200\n",
      "epoch4: se:56.000\n",
      "performance: 155/200\n",
      "epoch5: se:56.000\n",
      "performance: 154/200\n",
      "epoch6: se:36.000\n",
      "performance: 151/200\n",
      "epoch7: se:0.000\n",
      "performance: 151/200\n",
      "Elapsed time for a fold: 0.9638571739196777\n",
      "4-fold:\n",
      "epoch0: se:1552.000\n",
      "performance: 158/200\n",
      "epoch1: se:484.000\n",
      "performance: 156/200\n",
      "epoch2: se:252.000\n",
      "performance: 159/200\n",
      "epoch3: se:120.000\n",
      "performance: 156/200\n",
      "epoch4: se:28.000\n",
      "performance: 159/200\n",
      "epoch5: se:56.000\n",
      "performance: 161/200\n",
      "epoch6: se:8.000\n",
      "performance: 160/200\n",
      "epoch7: se:20.000\n",
      "performance: 161/200\n",
      "epoch8: se:0.000\n",
      "performance: 161/200\n",
      "Elapsed time for a fold: 1.5417098999023438\n",
      "5-fold:\n",
      "epoch0: se:1480.000\n",
      "performance: 151/200\n",
      "epoch1: se:588.000\n",
      "performance: 160/200\n",
      "epoch2: se:264.000\n",
      "performance: 164/200\n",
      "epoch3: se:152.000\n",
      "performance: 165/200\n",
      "epoch4: se:68.000\n",
      "performance: 162/200\n",
      "epoch5: se:36.000\n",
      "performance: 160/200\n",
      "epoch6: se:20.000\n",
      "performance: 161/200\n",
      "epoch7: se:20.000\n",
      "performance: 161/200\n",
      "epoch8: se:24.000\n",
      "performance: 162/200\n",
      "epoch9: se:0.000\n",
      "performance: 162/200\n",
      "Elapsed time for a fold: 1.7434368133544922\n",
      "6-fold:\n",
      "epoch0: se:1604.000\n",
      "performance: 141/200\n",
      "epoch1: se:460.000\n",
      "performance: 151/200\n",
      "epoch2: se:204.000\n",
      "performance: 153/200\n",
      "epoch3: se:96.000\n",
      "performance: 155/200\n",
      "epoch4: se:72.000\n",
      "performance: 156/200\n",
      "epoch5: se:32.000\n",
      "performance: 150/200\n",
      "epoch6: se:52.000\n",
      "performance: 150/200\n",
      "epoch7: se:24.000\n",
      "performance: 146/200\n",
      "epoch8: se:24.000\n",
      "performance: 146/200\n",
      "epoch9: se:8.000\n",
      "performance: 152/200\n",
      "epoch10: se:0.000\n",
      "performance: 152/200\n",
      "Elapsed time for a fold: 2.2730019092559814\n"
     ]
    }
   ],
   "source": [
    "# K-fold-cross-validation\n",
    "k = 7\n",
    "print(len(pos_neg))\n",
    "batch_num = int(len(pos_neg) / k)\n",
    "print(batch_num)\n",
    "dia = len(w_appeared)\n",
    "for i in range(k):\n",
    "    print(\"%d-fold:\"%i)\n",
    "    start = time.time()\n",
    "    test_set = pos_neg[i*batch_num:(i+1)*batch_num]\n",
    "    train_set = pos_neg[0:i*batch_num] + pos_neg[(i+1)*batch_num:len(pos_neg)]\n",
    "    svm = SVM(dia)\n",
    "    svm.train(train_set,0.5,15,test_set)\n",
    "    end = time.time()\n",
    "    print(\"Elapsed time for a fold:\",end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
